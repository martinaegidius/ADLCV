{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "from tqdm import tqdm\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "# custom imports\n",
    "from ddpm import Diffusion\n",
    "from model import Classifier, UNet\n",
    "from dataset.helpers import *\n",
    "from util import set_seed, prepare_dataloaders\n",
    "set_seed()\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super().__init__()\n",
    "        # https://pytorch.org/vision/main/models/generated/torchvision.models.vgg11.html\n",
    "        self.features = torchvision.models.vgg11(weights=torchvision.models.VGG11_Weights.DEFAULT).features[:10]\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x, features=False):\n",
    "        feat = self.features(x)\n",
    "        feat = self.avg_pool(feat)\n",
    "        x = self.dropout(self.flatten(feat))\n",
    "        x = self.fc(x)\n",
    "        if features:\n",
    "            return feat\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "def get_features(model, images):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        features = model(images, features=True)\n",
    "    features = features.squeeze(3).squeeze(2).cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def feature_statistics(features):\n",
    "    mu = np.mean(features, axis=0)\n",
    "    sigma = np.cov(features, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "def frechet_distance(mu1, sigma1, mu2, sigma2):\n",
    "    # https://en.wikipedia.org/wiki/Fr%C3%A9chet_distance\n",
    "    # HINT: https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.sqrtm.html\n",
    "    # Implement FID score\n",
    "    distance_term = np.power(linalg.norm(mu1-mu2),2)\n",
    "    trace_term = sigma1+sigma2-2*linalg.sqrtm(sigma1@sigma2)\n",
    "    trace_term = np.trace(trace_term)\n",
    "    fid = distance_term + trace_term\n",
    "    return fid\n",
    "#todo: debug by testing on 1. exactly same test-data (small dist), 2. pure noise (large dist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion type: DDPM-cg\n",
      "Diffusion type: DDPM-cFg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-8a719046.pth\" to /home/max/.var/app/com.visualstudio.code/cache/torch/hub/checkpoints/vgg11-8a719046.pth\n",
      "100%|██████████| 507M/507M [00:41<00:00, 12.9MB/s] \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;66;03m# vgg feature dim\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#_ ,_, test_loader = prepare_dataloaders(val_batch_size=100)\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m (test_loader\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     36\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m (test_loader\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39muint8) \n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "########################################### classifier guidance ##########################################\n",
    "ddpm_cg = Diffusion(img_size=16, T=500, beta_start=1e-4, beta_end=0.02, diff_type='DDPM-cg', device=device)\n",
    "classifier = Classifier(\n",
    "    img_size=16, c_in=3, labels=5,\n",
    "    time_dim=256,channels=32, device=device\n",
    ")\n",
    "classifier.to(device)\n",
    "classifier.eval()\n",
    "classifier.load_state_dict(torch.load('weights/classifier/model.pth', map_location=device))\n",
    "\n",
    "unet_ddpm = UNet(device=device)\n",
    "unet_ddpm.eval()\n",
    "unet_ddpm.to(device)\n",
    "unet_ddpm.load_state_dict(torch.load('weights/DDPM/model.pth', map_location=device))\n",
    "ddpm_cg.classifier = classifier\n",
    "\n",
    "######################################### classifier-free guidance #########################################\n",
    "ddpm_cFg = Diffusion(img_size=16, T=500, beta_start=1e-4, beta_end=0.02, diff_type='DDPM-cFg', device=device)\n",
    "unet_ddpm_cFg = UNet(num_classes=5, device=device)\n",
    "unet_ddpm_cFg.eval()\n",
    "unet_ddpm_cFg.to(device)\n",
    "unet_ddpm_cFg.load_state_dict(torch.load('weights/DDPM-cfg/model.pth', map_location=device))\n",
    "\n",
    "model = VGG()\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.load_state_dict(torch.load('weights/vgg-sprites/model.pth', map_location=device))\n",
    "dims = 256 # vgg feature dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_FID(mode=\"noise\",N_samples = 100):\n",
    "    if mode==\"noise\":\n",
    "        test_loader = [(torch.randn(1,3,16,16),None) for x in range(N_samples)] #noise image -> should give large FID\n",
    "        original_feat = np.empty((len(test_loader), dims))\n",
    "        generated_feat_cg = np.empty((len(test_loader), dims))\n",
    "        generated_feat_cFg = np.empty((len(test_loader), dims))\n",
    "    elif mode==\"equalData\":\n",
    "        _ ,_, test_loader = prepare_dataloaders(val_batch_size=100)\n",
    "        original_feat = np.empty((len(test_loader.dataset), dims))\n",
    "        generated_feat_cg = np.empty((len(test_loader.dataset), dims))\n",
    "        generated_feat_cFg = np.empty((len(test_loader.dataset), dims))\n",
    "\n",
    "    start_idx = 0\n",
    "\n",
    "    #for images, _ in tqdm(test_loader):\n",
    "    count = 0\n",
    "    for images, _ in tqdm(test_loader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        original = get_features(model, images)\n",
    "        \n",
    "        # classifier guidance\n",
    "        y = torch.randint(0, 5, (images.shape[0],), device=device)\n",
    "        if(mode==\"noise\"):\n",
    "            cg_images = ddpm_cg.p_sample_loop(unet_ddpm, images.shape[0], y=y, verbose=False)\n",
    "            cg_images = vgg_transform(cg_images/255.0)\n",
    "        elif(mode==\"equalData\"): #same test-data \n",
    "            cg_images = images\n",
    "\n",
    "        cg_features = get_features(model, cg_images)\n",
    "\n",
    "        # classifier-free guidance\n",
    "        #y = F.one_hot(y, num_classes=5).float()\n",
    "        #cFg_images = ddpm_cFg.p_sample_loop(unet_ddpm_cFg, images.shape[0], y=y, verbose=False)\n",
    "        #cFg_images = vgg_transform(cFg_images/255.0)\n",
    "        #cFg_features = get_features(model, cFg_images)\n",
    "\n",
    "        # store features\n",
    "        original_feat[start_idx:start_idx + original.shape[0]] = original\n",
    "        generated_feat_cg[start_idx:start_idx + original.shape[0]] = cg_features\n",
    "        #generated_feat_cFg[start_idx:start_idx + original.shape[0]] = cFg_features\n",
    "\n",
    "        start_idx = start_idx + original.shape[0]\n",
    "        count += 1 \n",
    "\n",
    "\n",
    "    mu_original, sigma_original = feature_statistics(original_feat)\n",
    "    mu_cg, sigma_cg = feature_statistics(generated_feat_cg)\n",
    "    #mu_cFg, sigma_cFg = feature_statistics(generated_feat_cFg)\n",
    "\n",
    "    fid_cg = frechet_distance(mu_original, sigma_original, mu_cg, sigma_cg)\n",
    "    #fid_cFg = frechet_distance(mu_original, sigma_original, mu_cFg, sigma_cFg)\n",
    "    print(f'[FID classifier guidance] {fid_cg:.3f}')\n",
    "    #print(f'[classifier-free guidance] {fid_cFg:.3f}')\n",
    "\n",
    "#frechet_results = {\"fid_cg\":fid_cg,\"fid_cFg\":fid_cFg,\n",
    "#                    \"mu_original\":mu_original,\"sigma_original\":sigma_original,\n",
    "#                    \"mu_cg\":mu_cg,\"sigma_cg\":sigma_cg,\n",
    "#                    \"mu_cFg\":mu_cFg,\"sigma_cFg\":sigma_cFg}\n",
    "#torch.save(frechet_results,\"frechet_results.pt\")\n",
    "    \n",
    "print(\"noise test:\")\n",
    "test_FID(mode=\"noise\")\n",
    "print(\"same image test:\")\n",
    "test_FID(mode=\"equalData\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
